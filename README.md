# Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates

This post describe a phenomenon, which goes by name “super-convergence”, where neural networks can be trained an order of magnitude faster than with standard training methods. One of the key elements of super-convergence is training with one cycle policy and a large maximum learning rate. A primary insight that allows super-convergence training is that large learning rates regularize the training, hence requiring a reduction of all other forms of regularization in order to preserve an optimal regularization balance.


